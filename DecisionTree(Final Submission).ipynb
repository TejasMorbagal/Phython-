{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the training data  from options below: \n",
      "  1. gene_expression_training.csv\n",
      "  2. gene_expression_test.csv\n",
      "  3. gene_expression_training_noise.csv\n",
      "  4. gene_expression_training_noise1.csv\n",
      "  5. Type the name of the file manually\n",
      "3\n",
      "Please choose the test data  from options below: \n",
      "  1. gene_expression_training.csv\n",
      "  2. gene_expression_test.csv\n",
      "  3. gene_expression_training_noise.csv\n",
      "  4. gene_expression_training_noise1.csv\n",
      "  5. Type the name of the file manually\n",
      "2\n",
      "Name of the dot file:  decision_tree.dot\n",
      "The following are the nodes created in the decision tree\n",
      "APP 0.42245 354 347 \n",
      "AMPKA 0.3156 162 272 \n",
      "Unnamed: 0 146.0 192 75 \n",
      "GluR3 0.26285000000000003 68 36 \n",
      "Unnamed: 0 125.5 94 236 \n",
      "S6 0.33165 65 24 \n",
      "JNK 0.18935 3 12 \n",
      "APP 0.39675000000000005 44 17 \n",
      "APP 0.3758 50 219 \n",
      "ELK 1.85445 16 37 \n",
      "pPKCG 1.25385 176 38 \n",
      "APP 0.4415 9 37 \n",
      "Unnamed: 0 0 7 0 \n",
      "pBRAF 0.1587 12 20 \n",
      "AMPKA 0.38655 164 18 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:187: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unnamed: 0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Unnamed: 0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ad0767c054bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;31m# Data set validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[0mdf_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m \u001b[0mtest_data_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-ad0767c054bf>\u001b[0m in \u001b[0;36mtest_data_output\u001b[1;34m(dftest, node_list)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[0mnumber_of_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrowaxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mpredict_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdftest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpredict_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mnumber_of_matches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-ad0767c054bf>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(row, dftest, node_list)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mcurrent_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_child_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2522\u001b[0m                       \u001b[1;34m\".at[] or .iat[] accessors instead\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m                       stacklevel=2)\n\u001b[1;32m-> 2524\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtakeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_box_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2532\u001b[1;33m         \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2533\u001b[0m         \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Unnamed: 0'"
     ]
    }
   ],
   "source": [
    "\n",
    "from random import choice \n",
    "from numpy import array, dot, random, asfarray\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import graphviz as gv\n",
    "import re\n",
    "import math\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# This is a node for building a tree.\n",
    "class TDIDTNode:\n",
    "\n",
    "    def __init__(self, parent_id=-1, left_child_id=None,right_child_id=None):\n",
    "        self.parent_id      = parent_id\n",
    "        self.is_Left         = False\n",
    "        #self.direction      = direction\n",
    "        self.left_child_id  = left_child_id\n",
    "        self.right_child_id = right_child_id\n",
    "        self.is_leaf        = False\n",
    "        self.outcome        = None\n",
    "        self.identifier      = 0\n",
    "        self.parent_test_outcome = None\n",
    "        self.pplus = None\n",
    "        self.pminus = None\n",
    "        self.label = None\n",
    "        self.threshold = None\n",
    "\n",
    "    def setLeftChild(self,id):\n",
    "        self.left_child_id = id\n",
    "\n",
    "    def setRightChild(self,id):\n",
    "        self.right_child_id = id\n",
    "\n",
    "    def setpplus(self,id):\n",
    "        self.pplus = id\n",
    "    \n",
    "    def setpminus(self,id):\n",
    "        self.pminus = id\n",
    "    \n",
    "    def setthreshold(self,id):\n",
    "        self.threshold = id\n",
    "\n",
    "    def setlabel(self,id):\n",
    "        self.label = id\n",
    "        \n",
    "    def setdirection(self, id):\n",
    "        self.direction = direction\n",
    "        \n",
    "    def setidentifier(self, id):\n",
    "        self.identifier = id\n",
    "        \n",
    "    def setis_Left(self, id):\n",
    "        self.is_Left = id\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{} {} {} {} \".format(self.label, self.threshold, self.pplus, self.pminus)\n",
    "\n",
    "# The function returns the information gain based on the positive and negative side split\n",
    "def get_information_gain(ppos = 335, pneg = 340, npos = 0, nneg = 8):\n",
    "    total = float(ppos + pneg + npos + nneg)\n",
    "    p_total = float(ppos + pneg)\n",
    "    n_total = float(npos + nneg)\n",
    "    information_gain = entropy((ppos+npos)/total,(pneg + nneg)/total)\n",
    "    if p_total > 0:\n",
    "        information_gain -= p_total/total * entropy(ppos/p_total,pneg/p_total)\n",
    "    if n_total > 0:\n",
    "        information_gain -= n_total/total * entropy(npos/n_total,nneg/n_total)\n",
    "    return information_gain\n",
    "\n",
    "# This calculates the entropy \n",
    "def entropy(p,n):\n",
    "    if n == 0:\n",
    "        return p*math.log(1.0/p, 2)\n",
    "    elif p == 0:\n",
    "        return n*math.log(1.0/n, 2)\n",
    "    return p*math.log(1.0/p, 2) + n*math.log(1.0/n, 2)\n",
    "\n",
    "#Read csv file into a dataframe\n",
    "def initialize_from_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "#This one calculates the total number of positive and negative outputs\n",
    "def number_of_positives(dflocal):\n",
    "    rowaxes, columnaxes = dflocal.axes\n",
    "    number_of_positives = 0\n",
    "    number_of_negatives = 0\n",
    "    for i in range(len(rowaxes)):\n",
    "        if(dflocal.iat[i,-1] == 1.0):\n",
    "            number_of_positives += 1\n",
    "        else :\n",
    "            number_of_negatives += 1\n",
    "    return number_of_positives, number_of_negatives \n",
    "\n",
    "# Determines the tree recursively by finding the best node heuristically\n",
    "def Create_tree_TDIDT(node_list, dfa, current_node_id, tree_depth):\n",
    "    current_node = node_list[current_node_id]\n",
    "    \n",
    "    rowaxes, columnaxes = dfa.axes\n",
    "    pplus, pminus = number_of_positives(dfa)\n",
    "    \n",
    "    network_information_gain = 0\n",
    "    final_mean = 0\n",
    "    node_attribute = 0\n",
    "    final_cutpoint = 0\n",
    "    \n",
    "    for current_column in range(len(columnaxes) - 1):\n",
    "        df_temp = dfa.sort_values(by=[columnaxes[current_column]])\n",
    "        sorted_array = df_temp[:][columnaxes[current_column]]\n",
    "        result = df_temp[:][columnaxes[-1]]\n",
    "        #print(result)\n",
    "        pinnerplus = 0\n",
    "        pinnerminus = 0\n",
    "        max_information_gain = 0\n",
    "        prev_out = 2\n",
    "        for i in range(len(rowaxes)):\n",
    "            if(df_temp.iat[i,-1] == 1.0):\n",
    "                pinnerplus +=1\n",
    "                information_gain = get_information_gain(ppos = pinnerplus, pneg = pinnerminus, \n",
    "                                     npos = (pplus - pinnerplus), nneg = (pminus - pinnerminus))\n",
    "                if(information_gain > max_information_gain):\n",
    "                    max_information_gain = information_gain\n",
    "                    potential_cutpoint = i\n",
    "                    if i > 0:\n",
    "                        potential_mean = (df_temp.iat[i, current_column] + \n",
    "                        df_temp.iat[i-1, current_column])/2;\n",
    "                    else:\n",
    "                        potential_mean =  df_temp.iat[i, current_column];\n",
    "            else:            \n",
    "                pinnerminus +=1\n",
    "        if(max_information_gain > network_information_gain):\n",
    "            network_information_gain = max_information_gain\n",
    "            node_attribute = current_column\n",
    "            final_mean = potential_mean\n",
    "            final_cutpoint = potential_cutpoint\n",
    "\n",
    "\n",
    "    # Updating the current array\n",
    "    current_node.threshold = final_mean\n",
    "    current_node.pplus = pplus\n",
    "    current_node.pminus = pminus\n",
    "    current_node.label = columnaxes[node_attribute]\n",
    "    # The array is sorted and split\n",
    "    df_temp = dfa.sort_values(by=[columnaxes[node_attribute]])\n",
    "    df1 = df_temp.iloc[:final_cutpoint, :]\n",
    "    df2 = df_temp.iloc[final_cutpoint:, :]\n",
    "    \n",
    "    if pplus == 0 or pminus == 0 or final_cutpoint == 0 or  tree_depth >= 3:\n",
    "        current_node.is_leaf = True\n",
    "        current_node.outcome = (pplus > pminus)\n",
    "        return\n",
    "    else:\n",
    "        current_node.is_leaf = False\n",
    "\n",
    "    left_node = TDIDTNode(current_node_id)\n",
    "    right_node = TDIDTNode(current_node_id)\n",
    "\n",
    "    current_node.left_child_id = len(node_list)\n",
    "    current_node.right_child_id = len(node_list)+1\n",
    "\n",
    "    # only needed to fullfill exercise requirements\n",
    "    left_node.identifier = current_node.left_child_id\n",
    "    right_node.identifier = current_node.right_child_id\n",
    "    left_node.parent_test_outcome = \"yes\"\n",
    "    right_node.parent_test_outcome = \"no\"\n",
    "\n",
    "    node_list.append(left_node)\n",
    "    node_list.append(right_node)\n",
    "    node_list[current_node.left_child_id].identifier = current_node.left_child_id;\n",
    "    node_list[current_node.right_child_id].identifier = current_node.right_child_id;\n",
    "#    node_list[current_node.left_child_id].is_Left = True\n",
    "    Create_tree_TDIDT(node_list,df1,current_node.left_child_id, tree_depth+1)\n",
    "    Create_tree_TDIDT(node_list,df2,current_node.right_child_id, tree_depth+1)\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "# Parses through the decision tree to find outcome.\n",
    "def classify(row, dftest,node_list):\n",
    "\n",
    "    current_node = node_list[0]\n",
    "\n",
    "    while not current_node.is_leaf:\n",
    "        if (dftest.get_value(row,str(current_node.label)) < current_node.threshold):\n",
    "            current_node = node_list[current_node.left_child_id]\n",
    "        else:\n",
    "            current_node = node_list[current_node.right_child_id]\n",
    "    return current_node.outcome\n",
    "\n",
    "# Compares the predicted output to actual output and prints the likelihood\n",
    "def test_data_output(dftest,node_list):\n",
    "    rowaxes, columnaxes = dftest.axes\n",
    "    number_of_matches = 0;\n",
    "    for row in range(len(rowaxes)):\n",
    "        predict_op = classify(row, dftest, node_list)\n",
    "        if(dftest.iat[row,-1] == predict_op): \n",
    "            number_of_matches += 1\n",
    "    print('Out of', len(rowaxes),'tests run, ',number_of_matches, \n",
    "          'matched the result which is at %',number_of_matches/len(rowaxes))\n",
    "\n",
    "# To write the node into dot file\n",
    "def Export_tree_node(node_list , index ): \n",
    "    if index == None:\n",
    "        return\n",
    "    Update_to_dot_file(node_list,node_list[index])\n",
    "    Export_tree_node(node_list , node_list[index].left_child_id )\n",
    "    Export_tree_node(node_list , node_list[index].right_child_id)\n",
    "\n",
    "# To write the node into dot file\n",
    "def Update_to_dot_file(node_list, node):\n",
    "\t#create node\n",
    "\tif(node.is_leaf and (node.outcome)):\n",
    "\t\tnode_description=str(node.identifier)+\" [ label=\\\"\"+node.label+\"[\"+str(node.pplus)+\" \"+str(node.pminus)+\"]\"+\"\\\" , fillcolor=\\\"#99ff99\\\"] ;\\n\"\n",
    "\telif(node.is_leaf and (node.outcome == False)):\n",
    "\t\tnode_description=str(node.identifier)+\" [ label=\\\"\"+node.label+\"[\"+str(node.pplus)+\" \"+str(node.pminus)+\"]\"+\"\\\" , fillcolor=\\\"#ff9999\\\"] ;\\n\"\n",
    "\telse:\n",
    "\t\tnode_description=str(node.identifier)+\" [ label=\\\"\"+node.label+\"[\"+str(node.pplus)+\" \"+str(node.pminus)+\"]\"+\"\\\" , fillcolor=\\\"#ffffff\\\"] ;\\n\"\n",
    "\n",
    "\tfo.write(node_description)\n",
    "\n",
    "\tif(node.parent_id!=-1):\n",
    "\t#create relation\n",
    "\t\tcondition = node.identifier % 2\n",
    "\t\tif(condition):\n",
    "\t\t\tnode_relation= str(node.parent_id)+\"->\"+str(node.identifier) + \" [labeldistance=2.5, labelangle=45, headlabel=\\\"<\"+str(node_list[node.parent_id].threshold)+\"\\\"] ;\\n\"\n",
    "\t\telse:\n",
    "\t\t\tnode_relation=str(node.parent_id)+\"->\"+str(node.identifier) + \" [labeldistance=2.5, labelangle=-45, headlabel=\\\">\"+str(node_list[node.parent_id].threshold)+\"\\\"] ;\\n\"\n",
    "\t\tfo.write(node_relation)\n",
    "\treturn\n",
    "\n",
    "def read_filename(file_type):\n",
    "    file_nr = 0\n",
    "    file_name = ''\n",
    "    while file_nr > 5 or file_nr < 1:\n",
    "        print('Please choose the',file_type, ' from options below: ')\n",
    "        print('  1. gene_expression_training.csv')\n",
    "        print('  2. gene_expression_test.csv')\n",
    "        print('  3. gene_expression_training_noise.csv')\n",
    "        print('  4. gene_expression_training_noise1.csv')\n",
    "        print('  5. Type the name of the file manually')\n",
    "        file_nr = int(input(''))\n",
    "        if file_nr > 0 and file_nr < 5:\n",
    "            switch ={ 1:'gene_expression_training.csv' , 2:'gene_expression_test.csv' , \n",
    "                     3:'gene_expression_training_noise.csv' , 4:'gene_expression_test_noise.csv'}\n",
    "            file_name = switch[file_nr]\n",
    "        elif file_nr == 5:\n",
    "            file_name = raw_input('Write the file path: ')\n",
    "        else: \n",
    "            print('Please choose one of the available options.')\n",
    "        \n",
    "        if not os.path.isfile(file_name):\n",
    "            print(\"The file \\'\" , file_name , \"\\' does not exists.\")\n",
    "            file_nr = 0\n",
    "            \n",
    "    return file_name\n",
    "\n",
    "# Training and test data\n",
    "training_file = read_filename('training data')\n",
    "test_file = read_filename('test data')\n",
    "\n",
    "# run TDIDT\n",
    "df = initialize_from_file(training_file)\n",
    "node_list = [TDIDTNode()]\n",
    "k = Create_tree_TDIDT(node_list,df,0,0)\n",
    "\n",
    "# For exporting the decision tree\n",
    "fo=open(\"decision_tree.dot\",\"w\")\n",
    "print(\"Name of the dot file: \",fo.name)\n",
    "fo.write(\"digraph Tree {\\nnode [shape=box, style=\\\"filled\\\", color=\\\"black\\\"] ;\\n\")\n",
    "\n",
    "Export_tree_node(node_list, 0)\n",
    "\n",
    "fo.write(\"}\")\n",
    "fo.close()\n",
    "\n",
    "# print all nodes created by TDIDT\n",
    "print('The following are the nodes created in the decision tree')\n",
    "for node in node_list:\n",
    "    print(node)\n",
    "\n",
    "\n",
    "# Data set validation\n",
    "df_validation = initialize_from_file(test_file)\n",
    "test_data_output(df_validation, node_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group dependent Tasks 5.3\n",
    "\n",
    "\n",
    "#def Add_noise_prob_1():\n",
    "df3 = pd.read_csv('gene_expression_training.csv')\n",
    "#len1 = len(df1.index)\n",
    "len1 = df3['class_label'].count()\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tejas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "C:\\Users\\Tejas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#creating Training Data with noise with probabilty 0.1\n",
    "#To classify the test data with \n",
    "count0= int( 0.1 * len1)\n",
    "count1 = int(0.1 * len1)\n",
    "index = 0\n",
    "#list1 = list()\n",
    "#list1 = df.iloc[:,-1].tolist()\n",
    "for val in df3.iloc[:,-1]:\n",
    "    if count1 > 0 or count0 > 0:\n",
    "        if float(val) == 1.0 and count1 > 0: \n",
    "           count1 = count1 - 1 \n",
    "           #df2['class_label'].replace(1.0,0.0)\n",
    "           df3.set_value(index,'class_label',0.0) \n",
    "        elif float(val) == 0.0 and count0 > 0:\n",
    "           count0 = count0 - 1\n",
    "           df3['class_label'].replace(0.0,1.0)\n",
    "           df3.set_value(index,'class_label',1.0)   \n",
    "    index = index + 1 \n",
    "#df2.drop(df2.columns[[-1,]], axis=1, inplace=True)   \n",
    "df3.to_csv('gene_expression_training_noise.csv')\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Training Data with noise with probability 0.25\n",
    "count0= int( 0.25 * len1)\n",
    "count1 = int(0.25 * len1)\n",
    "index = 0\n",
    "#list1 = list()\n",
    "#list1 = df.iloc[:,-1].tolist()\n",
    "for val in df2.iloc[:,-1]:\n",
    "    if count1 > 0 or count0 > 0:\n",
    "        if float(val) == 1.0 and count1 > 0: \n",
    "           count1 = count1 - 1 \n",
    "           #df2['class_label'].replace(1.0,0.0)\n",
    "           df2.set_value(index,'class_label',0.0) \n",
    "        elif float(val) == 0.0 and count0 > 0:\n",
    "           count0 = count0 - 1\n",
    "           df2['class_label'].replace(0.0,1.0)\n",
    "           df2.set_value(index,'class_label',1.0)   \n",
    "    index = index + 1 \n",
    "df2.drop(df2.columns[[-1,]], axis=1, inplace=True)   \n",
    "df2.to_csv('gene_expression_training_noise1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
